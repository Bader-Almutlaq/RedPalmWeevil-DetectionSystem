{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palm Weevil Trap Detection - Model Evaluation\n",
    "\n",
    "This notebook evaluates deep learning models trained to classify between Red Palm Weevil (RPW) traps and Non-RPW traps from images. We'll evaluate two models:\n",
    "1. MobileNetV3 Large\n",
    "2. EfficientNet B0\n",
    "\n",
    "## Overview\n",
    "- Load pre-trained models\n",
    "- Process test images with the same transformations used during training\n",
    "- Evaluate model performance on test data\n",
    "- Compare results between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import (\n",
    "    mobilenet_v3_large,\n",
    "    MobileNet_V3_Large_Weights,\n",
    "    efficientnet_b0,\n",
    "    EfficientNet_B0_Weights,\n",
    "    efficientnet_b4,\n",
    "    EfficientNet_B4_Weights,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Device setup - use GPU if available\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"mobilenet\": {\n",
    "        \"builder\": mobilenet_v3_large,\n",
    "        \"weights\": MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        \"classifier_index\": 0,\n",
    "        \"input_size\": 224,\n",
    "    },\n",
    "    \"efficientnet\": {\n",
    "        \"builder\": efficientnet_b0,\n",
    "        \"weights\": EfficientNet_B0_Weights.DEFAULT,\n",
    "        \"classifier_index\": 1,\n",
    "        \"input_size\": 224,\n",
    "    },\n",
    "    \"efficientnet_b4\": {\n",
    "        \"builder\": efficientnet_b4,\n",
    "        \"weights\": EfficientNet_B4_Weights.DEFAULT,\n",
    "        \"classifier_index\": 2,\n",
    "        \"input_size\": 380,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading Function\n",
    "\n",
    "This function loads our trained models from saved checkpoints. We're using two different architectures:\n",
    "1. MobileNetV3 Large - a lightweight model designed for mobile devices\n",
    "2. EfficientNet B0 - known for balancing accuracy and computational efficiency\n",
    "\n",
    "For both models, we've customized the classifier head to work with our binary classification task (RPW-trap vs NRPW-trap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, path, num_classes=2):\n",
    "    if model_name not in MODEL_CONFIGS:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    config = MODEL_CONFIGS[model_name]\n",
    "    model = config[\"builder\"](\n",
    "        weights=None\n",
    "    )  # Initialize the model without pre-trained weights\n",
    "\n",
    "    # Access the correct layer's in_features depending on the model\n",
    "    in_features = model.classifier[config[\"classifier_index\"]].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes),\n",
    "    )\n",
    "\n",
    "    # Load the trained weights from the path\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model.to(device)  # Move the model to the correct device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "We apply the same transformations that were used during model training:\n",
    "1. Resize images based on the model\n",
    "2. Convert to PyTorch tensors\n",
    "3. Normalize using ImageNet mean and standard deviation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(model_name):\n",
    "    if model_name not in MODEL_CONFIGS:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    model_config = MODEL_CONFIGS[model_name]\n",
    "    img_size = model_config[\"input_size\"]\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Function\n",
    "\n",
    "This function loads test images from their respective class folders and processes them using our transformation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_trap_images(folder_path, class_map):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for class_name, label in class_map.items():\n",
    "        class_folder = os.path.join(folder_path, class_name)\n",
    "        img_paths = glob.glob(os.path.join(class_folder, \"*.*\"))\n",
    "        if not img_paths:\n",
    "            print(f\"⚠️ Skipping {class_name} — no images found.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Found {len(img_paths)} images in class {class_name}\")\n",
    "        for img_path in img_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")  # No transform here\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    if not images:\n",
    "        return None, None\n",
    "\n",
    "    # Change this line to return raw images and labels (no transformation here)\n",
    "    return images, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Function\n",
    "\n",
    "This function evaluates model performance using:\n",
    "1. Accuracy metric\n",
    "2. Confusion matrix visualization\n",
    "\n",
    "The confusion matrix helps us understand false positives and false negatives in our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, class_names=None, show_cm=True):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device, non_blocking=(device.type == \"cuda\"))\n",
    "            labels = labels.to(device, non_blocking=(device.type == \"cuda\"))\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Infer class names if not provided\n",
    "    if (\n",
    "        class_names is None\n",
    "        and hasattr(test_loader.dataset, \"dataset\")\n",
    "        and hasattr(test_loader.dataset.dataset, \"classes\")\n",
    "    ):\n",
    "        class_names = test_loader.dataset.dataset.classes\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    print(f\"\\nEvaluation Metrics:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            all_labels, all_preds, target_names=class_names, zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Confusion matrix\n",
    "    if show_cm:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "        )\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Evaluation\n",
    "\n",
    "Now we'll load the test data and evaluate both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definitions\n",
    "class_names = [\"NRPW\", \"RPW\"]\n",
    "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# Load test data\n",
    "test_root = \"data\"\n",
    "print(f\"Loading test images from {test_root}...\")\n",
    "raw_images, raw_labels = load_raw_trap_images(test_root, class_to_idx)\n",
    "\n",
    "if raw_images is None or len(raw_images) == 0:\n",
    "    print(\"No images to evaluate. Please check your test data directory.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(raw_images)} test images in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Custom Dataset class\n",
    "class TrapImagesDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Apply transformation and create DataLoader\n",
    "def create_dataloader(images, labels, model_name, batch_size=32):\n",
    "    transform = get_transform(model_name)\n",
    "    dataset = TrapImagesDataset(images, labels, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV3 Evaluation\n",
    "\n",
    "MobileNetV3 is designed to be computationally efficient while maintaining good accuracy. Let's evaluate its performance on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the model (MobileNetV3)\n",
    "    print(\"\\n🔍 Loading MobileNetV3 model...\")\n",
    "    mobilenet = load_model(\"mobilenet\", \"saved_models/mobilenetv3_rpw.pth\")\n",
    "    print(\"MobileNetV3 model loaded successfully.\")\n",
    "\n",
    "    # Apply transformation and create DataLoader\n",
    "    test_loader = create_dataloader(raw_images, raw_labels, \"mobilenet\", batch_size=32)\n",
    "\n",
    "    # Now, pass the DataLoader to the evaluation function\n",
    "    mobilenet_acc, mobilenet_prec, mobilenet_rec, mobilenet_f1 = evaluate(\n",
    "        mobilenet, test_loader, class_names\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating MobileNetV3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet Evaluation\n",
    "\n",
    "EfficientNet is known for its scaling method that uniformly scales network width, depth, and resolution. Let's evaluate EfficientNet B0 on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the model (EfficientNetB0)\n",
    "    print(\"\\n🔍 Loading EfficientNetB0 model...\")\n",
    "    efficientnet = load_model(\"efficientnet\", \"saved_models/efficientnetb0_rpw.pth\")\n",
    "    print(\"EfficientNetB0 model loaded successfully.\")\n",
    "\n",
    "    # Apply transformation and create DataLoader\n",
    "    test_loader = create_dataloader(\n",
    "        raw_images, raw_labels, \"efficientnet\", batch_size=32\n",
    "    )\n",
    "\n",
    "    # Now, pass the DataLoader to the evaluation function\n",
    "    efficientnet_acc, efficientnet_prec, efficientnet_rec, efficientnet_f1 = evaluate(\n",
    "        efficientnet, test_loader, class_names\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating EfficientNetB0: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Let's compare the performance of both models side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Compare model accuracies\n",
    "    models = [\"MobileNetV3\", \"EfficientNetB0\"]\n",
    "    accuracies = [mobilenet_acc, efficientnet_acc]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(models, accuracies, color=['#3498db', '#2ecc71'])\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        plt.text(i, acc + 0.01, f'{acc:.4f}', ha='center')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print conclusion\n",
    "    better_model = \"MobileNetV3\" if mobilenet_acc > efficientnet_acc else \"EfficientNetB0\"\n",
    "    print(f\"\\nConclusion: {better_model} performed better on this test set with an accuracy of {max(accuracies):.4f}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error comparing models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we evaluated two deep learning models (MobileNetV3 and EfficientNetB0) on a palm weevil trap classification task. The evaluation metrics include:\n",
    "\n",
    "1. Overall accuracy\n",
    "2. Confusion matrix showing true positives, true negatives, false positives, and false negatives\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Based on the evaluation results, you might consider:\n",
    "- Using the better-performing model for deployment\n",
    "- Collecting more training data if accuracy is not satisfactory\n",
    "- Trying different model architectures or hyperparameters\n",
    "- Implementing ensemble methods to combine predictions from both models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
